{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**softmax**\n",
    "\n",
    "- $\\sigma$\t=\tsoftmax\n",
    "- $\\vec{z}$\t=\tinput vector\n",
    "- $e^{z_{i}}$\t=\tstandard exponential function for input vector\n",
    "- $K$\t=\tnumber of classes in the multi-class classifier\n",
    "- $e^{z_{j}}$\t=\tstandard exponential function for output vector\n",
    "- $e^{z_{j}}$\t=\tstandard exponential function for output vector\n",
    "\n",
    "------------\n",
    "![image](/Users/dimtriospanagoulias/Downloads/NLP_UNIPI/nlp_lab/Neuron2transformer/img_blog_image1_inline_(2).webp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mathematical Proof:\n",
    "\n",
    "- Let's call the max value c\n",
    "    - The modified formula is: $\\frac{e^{x_i-c}}{\\sum_{j=1}^n e^{x_j-c}}$\n",
    "    - This simplifies to: $\\frac{e^{x_i}/e^c}{\\sum_{j=1}^n e^{x_j}/e^c} = \\frac{e^{x_i}}{\\sum_{j=1}^n e^{x_j}}$\n",
    "\n",
    "- - Why Use This Form:\n",
    "\n",
    "    - Prevents numerical overflow\n",
    "    - Avoids inf values when dealing with large numbers\n",
    "    - More stable training in deep learning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
